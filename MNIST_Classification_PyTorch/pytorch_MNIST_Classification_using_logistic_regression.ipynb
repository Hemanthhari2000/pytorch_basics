{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e76dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a937c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fda134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='./data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b41ac8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cecafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='./data', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb94c88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf008f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x2353853C888>, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13ca9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1a39c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48205cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAN20lEQVR4nO3df6hc9ZnH8c8n2QYhSkwMSkh1bauSXcSmSwgLlphFG1wRkoItFZSEFa9/VK1QccVVKiyNYra7IoiQUG2ydK3FKEpZaSVINP4hRokaa6wxxDZNuEEFf/wRuzHP/nFPylXvfM91zpw5c/O8X3CZmfPcOedx4ueeM/M9Z76OCAE48c3qugEAw0HYgSQIO5AEYQeSIOxAEn8zzI3Z5qN/oGUR4amWN9qz277U9pu299q+tcm6ALTL/Y6z254t6Q+SviPpgKQXJV0ZEb8vPIc9O9CyNvbsyyXtjYh9EfEXSb+StLrB+gC0qEnYF0v606THB6pln2F7zPZO2zsbbAtAQ00+oJvqUOELh+kRsVHSRonDeKBLTfbsBySdOenxVyUdbNYOgLY0CfuLks61/TXbcyT9QNKTg2kLwKD1fRgfEUdtXy/pt5JmS3owIl4fWGcABqrvobe+NsZ7dqB1rZxUA2DmIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiaFO2QxMtnLlymJ927ZtxfqsWeV9VWn927dvLz73RMSeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYBZXtGrdunU9azfccEPxuRdccEGxXjfOvmvXrp61LVu2FJ97//33F+tHjx4t1rvUaxbXRifV2N4v6SNJn0o6GhHLmqwPQHsGcQbdP0XEuwNYD4AW8Z4dSKJp2EPS72y/ZHtsql+wPWZ7p+2dDbcFoIGmh/EXRsRB26dLetr2noh4dvIvRMRGSRslPqADutRozx4RB6vbw5Iel7R8EE0BGLy+w257ru1Tjt+XtErS7kE1BmCw+h5nt/11TezNpYm3A/8TET+teQ6H8SeY0ji6JF199dU9aytWrGi07bpx9mPHjvW97nPOOadYf+edd/ped9sGPs4eEfskfbPvjgAMFUNvQBKEHUiCsANJEHYgCcIOJMFXSZ/gTj311GJ96dKlxfpDDz1UrC9cuLBYP+mkk4r1kj179hTrdUNv5513Xt/bPhGxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnPwGsWbOmZ+3aa68tPnfVqlXFepuXkdbZsGFDsV7X26ZNmwbZzozHnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfQa46qqrivXNmze3tu26sew22VN+I/K0ddn7KOLVAJIg7EAShB1IgrADSRB2IAnCDiRB2IEkGGcfAXXj6Pfee2+xXrqm/MiRI8Xnjo+PF+unnHJKsb5gwYJivaSutw8//LBYnzdvXrHe5rX2M1Htnt32g7YP2949adkC20/bfqu6nd9umwCams5h/C8kXfq5ZbdK2hYR50raVj0GMMJqwx4Rz0p6/3OLV0s6fo7mZklrBtsWgEHr9z37GRFxSJIi4pDt03v9ou0xSWN9bgfAgLT+AV1EbJS0UZJsR9vbAzC1fofexm0vkqTq9vDgWgLQhn7D/qSktdX9tZKeGEw7ANpSexhv+2FJKyUttH1A0k8k3S3p17avkfRHSd9rs8mZrvS97lL99ehNxotfeOGFYv2SSy4p1tetW1esN/lu9ttuu61Yf/zxx4v1ut7wWbVhj4gre5QuHnAvAFrE6bJAEoQdSIKwA0kQdiAJwg4kwSWuA1A3BFR3iWqduktBS8NrN954Y6Nt13nllVeK9dKw4gMPPNBo248++mixXpquevny5Y22PROxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnH4A77rijWJ87d26j9a9fv75Yv+uuuxqtv2THjh3F+lNPPVWs131VdRMff/xxsf7JJ5+0tu2ZiD07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPs0LV26tGetblrjWbPKf1Nnz57dT0tDsXfv3q5b6JvtnrW6f5MTUb7/YiApwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2yvnnn1+sb926tWdt/vz5xec2mXIZvZ188snF+pw5c3rWMv6b1O7ZbT9o+7Dt3ZOW3Wn7z7Z3VT+XtdsmgKamcxj/C0mXTrH8vyJiafXzv4NtC8Cg1YY9Ip6V9P4QegHQoiYf0F1v+9XqML/nm1bbY7Z32t7ZYFsAGuo37A9I+oakpZIOSfpZr1+MiI0RsSwilvW5LQAD0FfYI2I8Ij6NiGOSNknKNyUmMMP0FXbbiyY9/K6k3b1+F8BoqB1nt/2wpJWSFto+IOknklbaXiopJO2XdF17LQ7HfffdV6yfddZZQ+oE03XFFVcU6xnnYC+pDXtEXDnF4p+30AuAFnG6LJAEYQeSIOxAEoQdSIKwA0lwiesQ3HLLLV23MCMtWbKkWL/nnnv6Xvf+/fuL9SNHjvS97lHFnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfQjee++9rlsYSXXj6E888USxftpppxXrhw8f7lmruzx2fHy8WJ+J2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKOiOFtzB7exr6kZ555plhfsWJFa9uePXt2a+tuW920yVu2bOlZW716daNt79u3r1i//PLLe9befPPNRtseZRHhqZazZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnr1x88cXF+iOPPNKzNm/evEbb3rFjR7Fe929Uuu67bjy57jvt7SmHbP9qzpw5xXpp2uS672Zfv359sf7YY48V6yfyWHpJ3+Psts+0/YztN2y/bvtH1fIFtp+2/VZ1O3/QTQMYnOkcxh+V9OOI+DtJ/yjph7b/XtKtkrZFxLmStlWPAYyo2rBHxKGIeLm6/5GkNyQtlrRa0ubq1zZLWtNSjwAG4Et9B53tsyV9S9ILks6IiEPSxB8E26f3eM6YpLGGfQJoaNpht32ypK2SboqID+s+uDkuIjZK2litY2Q/oANOdNMaerP9FU0E/ZcRcfwj0HHbi6r6Ikm9v8oTQOdqh948sQvfLOn9iLhp0vINkt6LiLtt3yppQUQUx3Fm8p79oosu6lnbunVr8bl1Q3OzZpX/5h47dqxYb1PT3rZv396zVrr8dTp1TK3X0Nt0DuMvlHS1pNds76qW3Sbpbkm/tn2NpD9K+t4A+gTQktqwR8QOSb3eoJfPRAEwMjhdFkiCsANJEHYgCcIOJEHYgSS4xHUAFi9eXKyPjZXPFr799tuL9S7H2UvTHkvSc889V6xfd911PWsffPBBXz2hjK+SBpIj7EAShB1IgrADSRB2IAnCDiRB2IEkGGcfAWvXri3Wb7755mJ9yZIlPWt79uwpPnfDhg3F+ttvv12sP//888U6ho9xdiA5wg4kQdiBJAg7kARhB5Ig7EAShB1IgnF24ATDODuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJFEbdttn2n7G9hu2X7f9o2r5nbb/bHtX9XNZ++0C6FftSTW2F0laFBEv2z5F0kuS1kj6vqSPI+I/pr0xTqoBWtfrpJrpzM9+SNKh6v5Htt+QVJ4CBcDI+VLv2W2fLelbkl6oFl1v+1XbD9qe3+M5Y7Z32t7ZrFUATUz73HjbJ0vaLumnEfGY7TMkvSspJP27Jg71/6VmHRzGAy3rdRg/rbDb/oqk30j6bUT85xT1syX9JiLOr1kPYQda1veFMLYt6eeS3pgc9OqDu+O+K2l30yYBtGc6n8Z/W9Jzkl6TdHzu4NskXSlpqSYO4/dLuq76MK+0LvbsQMsaHcYPCmEH2sf17EByhB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSRqv3BywN6V9M6kxwurZaNoVHsb1b4keuvXIHv7216FoV7P/oWN2zsjYllnDRSMam+j2pdEb/0aVm8cxgNJEHYgia7DvrHj7ZeMam+j2pdEb/0aSm+dvmcHMDxd79kBDAlhB5LoJOy2L7X9pu29tm/toodebO+3/Vo1DXWn89NVc+gdtr170rIFtp+2/VZ1O+Ucex31NhLTeBemGe/0tet6+vOhv2e3PVvSHyR9R9IBSS9KujIifj/URnqwvV/Ssojo/AQM2yskfSxpy/GptWzfI+n9iLi7+kM5PyL+dUR6u1NfchrvlnrrNc34OnX42g1y+vN+dLFnXy5pb0Tsi4i/SPqVpNUd9DHyIuJZSe9/bvFqSZur+5s18T/L0PXobSRExKGIeLm6/5Gk49OMd/raFfoaii7CvljSnyY9PqDRmu89JP3O9ku2x7puZgpnHJ9mq7o9veN+Pq92Gu9h+tw04yPz2vUz/XlTXYR9qqlpRmn878KI+AdJ/yzph9XhKqbnAUnf0MQcgIck/azLZqppxrdKuikiPuyyl8mm6Gsor1sXYT8g6cxJj78q6WAHfUwpIg5Wt4clPa6Jtx2jZPz4DLrV7eGO+/mriBiPiE8j4pikTerwtaumGd8q6ZcR8Vi1uPPXbqq+hvW6dRH2FyWda/trtudI+oGkJzvo4wtsz60+OJHtuZJWafSmon5S0trq/lpJT3TYy2eMyjTevaYZV8evXefTn0fE0H8kXaaJT+TflvRvXfTQo6+vS3ql+nm9694kPayJw7r/08QR0TWSTpO0TdJb1e2CEertvzUxtfermgjWoo56+7Ym3hq+KmlX9XNZ169doa+hvG6cLgskwRl0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DE/wNVwlzYcw7ZEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[21]\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24ef57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb1f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='./data', train=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56aeff6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "img_tensor.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123137da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "        [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "        [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "        [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[0,10:15,10:15])\n",
    "print(torch.max(img_tensor), torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0174b8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the image by passing in the 28x28 matrix\n",
    "plt.imshow(img_tensor[0,10:15,10:15], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1408994",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e085945e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71402fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'dataset',\n",
       " 'indices']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4df0727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_ds.indices\n",
    "train_ds.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c32dfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f09d010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  128\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "====================================================================================================\n",
      "128\n",
      "Batch Size:  tensor([9, 7, 0, 2, 7, 1, 1, 8, 3, 9, 6, 0, 0, 1, 0, 8, 9, 5, 2, 1, 8, 4, 8, 7,\n",
      "        1, 9, 2, 2, 6, 9, 0, 4, 9, 3, 9, 9, 9, 4, 5, 3, 8, 0, 5, 7, 6, 0, 2, 6,\n",
      "        1, 4, 4, 4, 9, 3, 3, 3, 0, 5, 0, 3, 7, 5, 8, 0, 9, 4, 4, 9, 7, 6, 5, 6,\n",
      "        2, 6, 5, 0, 9, 7, 7, 6, 8, 9, 2, 2, 6, 3, 0, 5, 7, 9, 5, 4, 0, 0, 9, 2,\n",
      "        8, 8, 8, 3, 4, 0, 9, 8, 6, 0, 7, 6, 7, 2, 8, 7, 8, 4, 6, 4, 4, 2, 4, 9,\n",
      "        8, 6, 0, 6, 0, 5, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "# dir(train_loader)\n",
    "for xb, yb in train_loader:\n",
    "    print('Batch Size: ',len(xb))\n",
    "    print(xb)\n",
    "    print('='*100)\n",
    "    print(len(yb))\n",
    "    print('Batch Size: ',yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958f1ab",
   "metadata": {},
   "source": [
    "**We now see that `xb` has all the image tensor and `yb` has the required class**\n",
    "\n",
    "Here, we get an output of `128 image tensors` with `128 classes or label` values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436ff9ba",
   "metadata": {},
   "source": [
    "## Define a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c2457d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5958a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "# print(model.weight)\n",
    "print(model.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521bdf0",
   "metadata": {},
   "source": [
    "If we now try to give the model the input of tensor images then we would get an **error** like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f818a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 8, 2, 0, 3, 6, 8, 7, 6, 2, 0, 5, 6, 9, 2, 0, 4, 1, 7, 0, 4, 6, 8,\n",
      "        3, 5, 1, 6, 4, 0, 6, 9, 5, 1, 1, 5, 2, 4, 1, 2, 4, 0, 5, 9, 3, 4, 2, 3,\n",
      "        0, 3, 1, 3, 5, 7, 7, 1, 9, 8, 5, 1, 7, 6, 6, 7, 4, 1, 1, 8, 0, 2, 8, 8,\n",
      "        5, 8, 8, 1, 0, 5, 7, 6, 0, 8, 5, 5, 8, 6, 1, 8, 7, 0, 3, 4, 7, 1, 7, 9,\n",
      "        8, 1, 9, 2, 7, 8, 4, 7, 2, 8, 3, 6, 7, 2, 3, 3, 9, 1, 1, 5, 9, 8, 7, 1,\n",
      "        4, 4, 2, 7, 4, 6, 9, 6])\n",
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [3584 x 28], m2: [784 x 10] at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-d0fe7d306f83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [3584 x 28], m2: [784 x 10] at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    print(outputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c89f6e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b408e0",
   "metadata": {},
   "source": [
    "we need to reshape the images as `[128, 784]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ede7498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.reshape(128, input_size).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ee861",
   "metadata": {},
   "source": [
    "# Create a Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9d02a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, input_size)\n",
    "        out = self.linear(xb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ab7e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a461567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff278bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad84366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model Parameters:\n",
      " Weights Shape:\t torch.Size([10, 784])\n",
      " Bias Shape: \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(f'[INFO] Model Parameters:\\n Weights Shape:\\t {model.linear.weight.shape}\\n Bias Shape: \\t {model.linear.bias.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30466a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0112,  0.0134,  0.0136,  ..., -0.0298, -0.0138, -0.0121],\n",
       "         [-0.0272, -0.0042,  0.0350,  ..., -0.0162,  0.0137,  0.0293],\n",
       "         [ 0.0231,  0.0047, -0.0133,  ...,  0.0281,  0.0151,  0.0349],\n",
       "         ...,\n",
       "         [ 0.0357,  0.0187, -0.0186,  ...,  0.0004, -0.0226, -0.0311],\n",
       "         [ 0.0296, -0.0174,  0.0205,  ..., -0.0111,  0.0002,  0.0080],\n",
       "         [-0.0268, -0.0186, -0.0177,  ..., -0.0118,  0.0075, -0.0080]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0009,  0.0136,  0.0074,  0.0111, -0.0023, -0.0191,  0.0230,  0.0236,\n",
       "          0.0304, -0.0219], requires_grad=True)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aba2afb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Image Size: torch.Size([128, 1, 28, 28])\n",
      "outputs.shape:\ttorch.Size([128, 10])\n",
      "Sample outputs:\ttensor([[ 0.1001,  0.0885,  0.2396, -0.0328, -0.0120, -0.1519,  0.0997, -0.0547,\n",
      "          0.2307,  0.0314]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f'Batch Image Size: {images.shape}')\n",
    "    outputs = model(images)\n",
    "    break\n",
    "print(f'outputs.shape:\\t{outputs.shape}\\nSample outputs:\\t{outputs[:1].data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71422557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "979c693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1001,  0.0885,  0.2396, -0.0328, -0.0120, -0.1519,  0.0997, -0.0547,\n",
       "          0.2307,  0.0314],\n",
       "        [-0.0311, -0.0373,  0.0942,  0.1708, -0.3437,  0.0628, -0.0751,  0.0255,\n",
       "         -0.0419, -0.0274]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb45082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Probabilities:  tensor([[0.1040, 0.1028, 0.1196, 0.0911, 0.0930, 0.0808, 0.1040, 0.0891, 0.1185,\n",
      "         0.0971]])\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "print('Sample Probabilities: ', probs[:1].data)\n",
    "\n",
    "print('Sum: ', torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c806353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1196, 0.1201, 0.1168, 0.1374, 0.1162, 0.1193, 0.1292, 0.1122, 0.1268,\n",
      "        0.1321, 0.1179, 0.1375, 0.1257, 0.1239, 0.1092, 0.1192, 0.1394, 0.1324,\n",
      "        0.1156, 0.1309, 0.1154, 0.1302, 0.1199, 0.1198, 0.1179, 0.1238, 0.1232,\n",
      "        0.1343, 0.1250, 0.1339, 0.1137, 0.1458, 0.1145, 0.1295, 0.1220, 0.1466,\n",
      "        0.1490, 0.1277, 0.1249, 0.1214, 0.1243, 0.1135, 0.1514, 0.1312, 0.1385,\n",
      "        0.1161, 0.1186, 0.1161, 0.1215, 0.1516, 0.1246, 0.1360, 0.1126, 0.1205,\n",
      "        0.1216, 0.1278, 0.1320, 0.1280, 0.1212, 0.1160, 0.1209, 0.1202, 0.1224,\n",
      "        0.1303, 0.1236, 0.1244, 0.1259, 0.1259, 0.1208, 0.1276, 0.1295, 0.1162,\n",
      "        0.1260, 0.1116, 0.1237, 0.1204, 0.1273, 0.1348, 0.1278, 0.1219, 0.1203,\n",
      "        0.1144, 0.1486, 0.1092, 0.1208, 0.1258, 0.1232, 0.1226, 0.1309, 0.1233,\n",
      "        0.1183, 0.1216, 0.1184, 0.1176, 0.1496, 0.1172, 0.1251, 0.1132, 0.1220,\n",
      "        0.1322, 0.1185, 0.1501, 0.1267, 0.1428, 0.1511, 0.1244, 0.1329, 0.1267,\n",
      "        0.1184, 0.1092, 0.1413, 0.1305, 0.1146, 0.1262, 0.1183, 0.1299, 0.1383,\n",
      "        0.1307, 0.1395, 0.1212, 0.1148, 0.1275, 0.1181, 0.1345, 0.1292, 0.1195,\n",
      "        0.1205, 0.1255], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(max_probs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eaa025",
   "metadata": {},
   "source": [
    "`max_probs`: gives us the indices `preds`: gives us the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fcf8b777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 9, 2, 7, 9, 9, 7, 9, 0, 6, 9, 5, 5, 4, 1, 2, 0, 7, 5, 3, 8, 2, 5, 5,\n",
       "        5, 3, 3, 2, 7, 7, 7, 3, 4, 7, 7, 8, 4, 0, 2, 7, 8, 0, 0, 3, 7, 0, 8, 2,\n",
       "        4, 8, 5, 0, 1, 6, 1, 3, 2, 6, 0, 2, 8, 7, 9, 6, 9, 9, 9, 2, 4, 5, 0, 3,\n",
       "        4, 1, 6, 0, 0, 2, 8, 4, 0, 0, 2, 8, 1, 3, 8, 7, 4, 4, 9, 0, 2, 6, 8, 3,\n",
       "        3, 9, 4, 3, 3, 5, 8, 0, 3, 9, 0, 3, 5, 6, 0, 9, 2, 0, 4, 2, 0, 0, 2, 4,\n",
       "        2, 2, 3, 8, 0, 1, 8, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc0126",
   "metadata": {},
   "source": [
    "# Evaluation Metric and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a58112d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1001,  0.0885,  0.2396, -0.0328, -0.0120, -0.1519,  0.0997, -0.0547,\n",
       "          0.2307,  0.0314],\n",
       "        [-0.0311, -0.0373,  0.0942,  0.1708, -0.3437,  0.0628, -0.0751,  0.0255,\n",
       "         -0.0419, -0.0274]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "206311e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1796875"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(preds==labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24a7b4",
   "metadata": {},
   "source": [
    "This means that we got 23 right predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae6cc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d59e044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1797)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db828b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1040, 0.1028, 0.1196,  ..., 0.0891, 0.1185, 0.0971],\n",
       "        [0.0981, 0.0975, 0.1112,  ..., 0.1039, 0.0971, 0.0985],\n",
       "        [0.1150, 0.0830, 0.0926,  ..., 0.0939, 0.0902, 0.1168],\n",
       "        ...,\n",
       "        [0.0949, 0.1155, 0.1195,  ..., 0.0935, 0.1042, 0.1085],\n",
       "        [0.1205, 0.0994, 0.0874,  ..., 0.1123, 0.0935, 0.0984],\n",
       "        [0.0888, 0.0947, 0.1152,  ..., 0.0879, 0.1255, 0.1049]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c604d7c",
   "metadata": {},
   "source": [
    "we dont get better results when we use gradient descent instead for classification problems we can use some thing called `cross_entropy` which are idle for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "27d150ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1001,  0.0885,  0.2396,  ..., -0.0547,  0.2307,  0.0314],\n",
       "        [-0.0311, -0.0373,  0.0942,  ...,  0.0255, -0.0419, -0.0274],\n",
       "        [ 0.1362, -0.1901, -0.0807,  ..., -0.0670, -0.1065,  0.1518],\n",
       "        ...,\n",
       "        [-0.0300,  0.1659,  0.2000,  ..., -0.0453,  0.0628,  0.1040],\n",
       "        [ 0.2853,  0.0930, -0.0357,  ...,  0.2142,  0.0311,  0.0825],\n",
       "        [ 0.0024,  0.0668,  0.2627,  ..., -0.0076,  0.3490,  0.1690]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e9ed1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f94f9743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2773, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(outputs, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242092f",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f85f4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    opt = opt_func(model.parameters(), lr)\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8316b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf94bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = [x*2 for x in l1]\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e07782c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa065abc",
   "metadata": {},
   "source": [
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "465a6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, input_size)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return {'val_loss':loss, 'val_acc':acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26051236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    opt = opt_func(model.parameters(), lr)\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2fc0dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "97bc3756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3346784114837646, 'val_acc': 0.0914754718542099}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "48761727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.9631, val_acc: 0.6225\n",
      "Epoch [1], val_loss: 1.6888, val_acc: 0.7342\n",
      "Epoch [2], val_loss: 1.4845, val_acc: 0.7667\n",
      "Epoch [3], val_loss: 1.3306, val_acc: 0.7838\n",
      "Epoch [4], val_loss: 1.2127, val_acc: 0.7958\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fd28f379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.1203, val_acc: 0.8050\n",
      "Epoch [1], val_loss: 1.0463, val_acc: 0.8123\n",
      "Epoch [2], val_loss: 0.9858, val_acc: 0.8204\n",
      "Epoch [3], val_loss: 0.9356, val_acc: 0.8249\n",
      "Epoch [4], val_loss: 0.8931, val_acc: 0.8286\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "66231b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.8569, val_acc: 0.8330\n",
      "Epoch [1], val_loss: 0.8255, val_acc: 0.8360\n",
      "Epoch [2], val_loss: 0.7980, val_acc: 0.8378\n",
      "Epoch [3], val_loss: 0.7737, val_acc: 0.8403\n",
      "Epoch [4], val_loss: 0.7521, val_acc: 0.8427\n"
     ]
    }
   ],
   "source": [
    "history3 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f5281a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.7327, val_acc: 0.8449\n",
      "Epoch [1], val_loss: 0.7153, val_acc: 0.8468\n",
      "Epoch [2], val_loss: 0.6994, val_acc: 0.8487\n",
      "Epoch [3], val_loss: 0.6850, val_acc: 0.8509\n",
      "Epoch [4], val_loss: 0.6717, val_acc: 0.8524\n"
     ]
    }
   ],
   "source": [
    "history4 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b63e3656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs No. of epochs')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = [result0] + history1 + history2 + history3 + history4\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-rx')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs No. of epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dede79",
   "metadata": {},
   "source": [
    "# Testing with individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6511b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root = './data', train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fd11f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([1, 28, 28])\n",
      "Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Shape: ', img.shape)\n",
    "print('Label: ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cf78ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821461f",
   "metadata": {},
   "source": [
    "`img.unsqueeze` simply adds another dimension at the begining of the 1x28x28 tensor, making it a 1x1x28x28 tensor, which the model views as a batch containing a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "054e26bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7 Predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, 'Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "09b20099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6405271291732788, 'val_acc': 0.862597644329071}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size = 256)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca72f2",
   "metadata": {},
   "source": [
    "# Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "da44ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist-logistic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a5c3111e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0022,  0.0090,  0.0020,  ..., -0.0058,  0.0165,  0.0241],\n",
       "                      [-0.0185, -0.0187, -0.0226,  ...,  0.0077,  0.0301,  0.0031],\n",
       "                      [-0.0265, -0.0161,  0.0212,  ...,  0.0342,  0.0213, -0.0121],\n",
       "                      ...,\n",
       "                      [ 0.0090,  0.0133,  0.0055,  ..., -0.0323, -0.0140,  0.0246],\n",
       "                      [ 0.0350, -0.0081, -0.0297,  ..., -0.0006,  0.0329, -0.0316],\n",
       "                      [ 0.0164,  0.0093, -0.0074,  ...,  0.0266,  0.0100,  0.0283]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0549,  0.1220, -0.0290, -0.0098,  0.0411,  0.0191, -0.0068,  0.0094,\n",
       "                      -0.0659,  0.0023]))])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedf11a",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "356bbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "43e8d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('mnist-logistic.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a20d4a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0022,  0.0090,  0.0020,  ..., -0.0058,  0.0165,  0.0241],\n",
       "                      [-0.0185, -0.0187, -0.0226,  ...,  0.0077,  0.0301,  0.0031],\n",
       "                      [-0.0265, -0.0161,  0.0212,  ...,  0.0342,  0.0213, -0.0121],\n",
       "                      ...,\n",
       "                      [ 0.0090,  0.0133,  0.0055,  ..., -0.0323, -0.0140,  0.0246],\n",
       "                      [ 0.0350, -0.0081, -0.0297,  ..., -0.0006,  0.0329, -0.0316],\n",
       "                      [ 0.0164,  0.0093, -0.0074,  ...,  0.0266,  0.0100,  0.0283]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0549,  0.1220, -0.0290, -0.0098,  0.0411,  0.0191, -0.0068,  0.0094,\n",
       "                      -0.0659,  0.0023]))])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbaf598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d702ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
